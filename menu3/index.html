<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/highlight/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/jemdoc.css"> <link rel=icon  href="/assets/favicon.png"> <title>CUDA in Julia</title> <main class=outside > <div class=box > <aside class=layout-menu > <div class=menu-category >Julia in HPC</div> <div class="menu-item "><a href="/">Home</a></div> <div class=menu-category >topics</div> <div class="menu-item "><a href="/menu1/">Functional programming</a></div> <div class="menu-item "><a href="/menu2/">MPI in Julia</a></div> <div class="menu-item current"><a href="/menu3/">CUDA in Julia</a></div> <div class="menu-item "><a href="/menu4/">CUDA-aware MPI</a></div> <div class="menu-item "><a href="/menu5/">MAGMA.jl</a></div> </aside> <div class=layout-content > <div class=franklin-content > <h1 id=cuda_in_julia ><a href="#cuda_in_julia" class=header-anchor >CUDA in Julia</a></h1> <div class=franklin-toc ><ol><li><a href="#cudajl">CUDA.jl</a><li><a href="#how_to_rewrite_a_cpu_code_to_a_gpu_code">How to rewrite a CPU code to a GPU code</a><li><a href="#how_to_write_a_kernel_function">How to write a kernel function</a><li><a href="#type-unstable_way_to_make_cpu_and_gpu_codes_coexist">Type-unstable way to make CPU and GPU codes coexist</a><li><a href="#type-stable_way_to_make_cpu_and_gpu_codes_coexist">Type-stable way to make CPU and GPU codes coexist</a></ol></div> <h2 id=cudajl ><a href="#cudajl" class=header-anchor >CUDA.jl</a></h2> <p>CUDA.jl is the Julia version of the CUDA library, which offers a GPGPU plarform for NVIDIA GPU. CUDA.jl is not just a wrapper for CUDA functions, but also has functionality to compile the kernel code. CUDA.jl completely natively supports Julia, i.e. you can use a native Julia code to write a kernel function like a script language. The JIT compilation completely works.</p> <h2 id=how_to_rewrite_a_cpu_code_to_a_gpu_code ><a href="#how_to_rewrite_a_cpu_code_to_a_gpu_code" class=header-anchor >How to rewrite a CPU code to a GPU code</a></h2> <ul> <li><p>Add <code>CUDA.</code> for initialization functions.</p> <ul> <li><p><code>zeros&#40;m, n&#41;</code> -&gt; <code>CUDA.zeros&#40;Float64, m, n&#41;</code></p> <li><p><code>rand&#40;m, n&#41;</code> -&gt; <code>CUDA.rand&#40;Float64, m, n&#41;</code></p> </ul> <li><p>Sometimes call a function <code>CUDA.synchronize&#40;&#41;</code>.</p> <li><p>Call kernel functions with <code>@cuda</code> macro.</p> <li><p>Replace BLAS with CUBLAS.</p> <li><p>Replace LAPACK with cuSOLVER or MAGMA. &#40;I recommend <a href="https://icl.cs.utk.edu/magma/">MAGMA</a>.&#41;</p> <li><p>Please be aware where your data are, on CPU, or on GPU.</p> </ul> <p>These are the only things you have to do to make your CPU code work in GPU. CUDA versions are included in CUDA.jl for most of the <code>Base</code>/<code>LinearAlgebra</code> functions. Essentially, just by changing initialization functions, Julia&#39;s multiple dispatch automatically changes CPU methods to GPU methods. Only you have to do is to be aware of types, <code>Array</code> or <code>CuArray</code>, <code>Vector</code> or <code>CuVector</code>, <code>Matrix</code> or <code>CuMatrix</code>. This nice switch with the same functions thanks to the multiple dispatch paradigm even allows us to write a code which works both in CPU and in GPU at the same time.</p> <h2 id=how_to_write_a_kernel_function ><a href="#how_to_write_a_kernel_function" class=header-anchor >How to write a kernel function</a></h2> <h2 id=type-unstable_way_to_make_cpu_and_gpu_codes_coexist ><a href="#type-unstable_way_to_make_cpu_and_gpu_codes_coexist" class=header-anchor >Type-unstable way to make CPU and GPU codes coexist</a></h2> <p>You can easily make CPU and GPU codes coexist in your own code. Here&#39;s an example.</p> <pre><code class="julia hljs"><span class=hljs-keyword >using</span> LinearAlgebra
<span class=hljs-keyword >using</span> CUDA

<span class=hljs-keyword >function</span> power_iteration(m, gpu)
    <span class=hljs-keyword >if</span> gpu
        A = CUDA.rand(m, m)
        b = CUDA.rand(m)
    <span class=hljs-keyword >else</span>
        A = rand(<span class=hljs-built_in >Float32</span>, m, m)
        b = rand(<span class=hljs-built_in >Float32</span>, m)
    <span class=hljs-keyword >end</span>

    <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:<span class=hljs-number >100</span>
        b .= A * b
        b ./= norm(b)
    <span class=hljs-keyword >end</span>

    dot(b, A * b)
<span class=hljs-keyword >end</span></code></pre> <p>The code works in GPU when <code>gpu &#61; true</code> and in CPU when <code>gpu &#61; false</code>. The point is that you do not have to write the main algorithm of the power iteration twice. It is enough to have an <code>if</code> syntax in the initialization. However, this code is very type-unstable. You can check that by <code>@code_warntype power_iteration&#40;100, true&#41;</code> for example.</p> <h2 id=type-stable_way_to_make_cpu_and_gpu_codes_coexist ><a href="#type-stable_way_to_make_cpu_and_gpu_codes_coexist" class=header-anchor >Type-stable way to make CPU and GPU codes coexist</a></h2> <p>Unfortunately, the above way of switching CPU and GPU by the <code>Bool</code> value <code>gpu</code> causes type instability. There are many ways to avoid this problem. Here&#39;s one simple way to make it type-stable.</p> <p>First, define the following abstract types:</p> <pre><code class="julia hljs"><span class=hljs-keyword >abstract type</span> Engine <span class=hljs-keyword >end</span>
<span class=hljs-keyword >abstract type</span> CPUEngine &lt;: Engine <span class=hljs-keyword >end</span>
<span class=hljs-keyword >abstract type</span> GPUEngine &lt;: Engine <span class=hljs-keyword >end</span></code></pre> <p>These abstract types seem meaningless, but they have an important role to give information to the compiler. Then, you should give an argument <code>engine</code> instead of <code>gpu</code>. <code>engine</code> should only take <code>CPUEngine</code> or <code>GPUEngine</code>, depending on which kernel you use.</p> <p>Finally, it is enough to add the following one line at the beginning of every function:</p> <pre><code class="julia hljs">gpu = engine &lt;: GPUEngine</code></pre>
<p>This automatically enables us to give CPU or GPU information to the compiler. Every <code>if gpu</code> syntax is inferred from the type of inputs, so it is enough to make everything type-stable.</p>
<pre><code class="julia hljs"><span class=hljs-keyword >using</span> LinearAlgebra
<span class=hljs-keyword >using</span> CUDA

<span class=hljs-keyword >abstract type</span> Engine <span class=hljs-keyword >end</span>
<span class=hljs-keyword >abstract type</span> CPUEngine &lt;: Engine <span class=hljs-keyword >end</span>
<span class=hljs-keyword >abstract type</span> GPUEngine &lt;: Engine <span class=hljs-keyword >end</span>

<span class=hljs-keyword >function</span> power_iteration(m, engine)
    gpu = engine &lt;: GPUEngine

    <span class=hljs-keyword >if</span> gpu
        A = CUDA.rand(m, m)
        b = CUDA.rand(m)
    <span class=hljs-keyword >else</span>
        A = rand(<span class=hljs-built_in >Float32</span>, m, m)
        b = rand(<span class=hljs-built_in >Float32</span>, m)
    <span class=hljs-keyword >end</span>

    <span class=hljs-keyword >for</span> i <span class=hljs-keyword >in</span> <span class=hljs-number >1</span>:<span class=hljs-number >100</span>
        b .= A * b
        b ./= norm(b)
    <span class=hljs-keyword >end</span>

    dot(b, A * b)
<span class=hljs-keyword >end</span></code></pre>
<p>One advantage of using abstract types is that you can add your own &quot;sub-engines&quot; to <code>CPUEngine</code> or <code>GPUEngine</code>. For example, you can add:</p>
<pre><code class="julia hljs"><span class=hljs-keyword >abstract type</span> MultiGPUEngine &lt;: GPUEngine <span class=hljs-keyword >end</span></code></pre>
<p>to write a multi-GPU code.</p>
<div class=page-foot >
  <div class=copyright >
    &copy; Masahiko G. Yamada. Last modified: September 15, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div>
        </div>
    
    
        


    
    </div>
  </main>